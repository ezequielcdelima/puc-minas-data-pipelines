1 - criar a pasta desafio final

2 - Instalar a ferramenta kubectl (linha de comando para administração do kubernetes)
https://kubernetes.io/docs/tasks/tools/install-kubectl-windows/

3 - Instalar helm https://helm.sh/docs/intro/install/

4 - Instalar  eksctl https://eksctl.io/introduction/#installation

5 - criar um usuario no iam da aws chamada airflow-user e guardar as chaves dele

6 - Instalar  o aws cli   linha de comando da aws https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html

7 - Armanezando as credenciais da aws na maquina
aws configure
AWS Access Key ID [None]: AKIARQS4E4JRQ6FKHIOQ
AWS Secret Access Key [None]: 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
Default region name [None]: us-east-1
Default output format [None]: json

8 - criar o cluster kubernetes
eksctl create cluster --version=1.21 --name=kubece --timeout=60m0s --managed --instance-types=m5.xlarge --alb-ingress-access --node-private-networking --region=us-east-1 --nodes-min=2 --nodes-max=3 --full-ecr-access --asg-access --nodegroup-name=ng-kubece

9 - lista os cluster kubernetes
kubectl config  get-contexts

10 - lista os nos do cluster kubernetes
kubectl get nodes

11 - lista os namespaces do cluster
kubectl get namespaces

12 - lista os pods (onde fica os containes rodadando no kubernetes)
kubectl get pods -n kube-system

13 - criando um namespaces para o airflow
kubectl create namespace airflow

14 - instala o hemlchar do airflow na maquina
helm repo add apache-airflow https://airflow.apache.org

15 - recupera o arquivo de values do helm char para deploy do airflow
helm show values apache-airflow/airflow >> airflow/custom_values.yaml


16 - no arquivo custom_values.yaml alterar
    executor: "KubernetesExecutor" 
    # antes de alterar isso é preciso criar um bucket no s3 para receber os logs do airflow
    env: 
    - name: AIRFLOW__LOGGING__REMOTE_LOGGING
        value: 'True'
    - name: AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER
        value: 's3://airflow-logs-104346215011/logs/'
    - name: AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID
        value: 'my_aws'

    defaultUser:
        enabled: true
        role: Admin
        username: carlos.ezequiel
        email: carlos.ezequiel@example.com
        firstName: Carlos
        lastName: Ezequiel
        password: admin

    service:
        type: LoadBalancer

    redis: # nao precisa pois nao vai subir com o modo padrao do airflow
        enabled: false

    gitSync: # permite vingular o  airflow no repositorio git
        enabled: true

    repo: https://github.com/ezequielcdelima/puc-minas-data-pipelines.git

    branch: master

    subPath: "dags"


17 - realizar o deploy do airflow no cluster kubernetes 
helm install airflow apache-airflow/airflow -f airflow/custom_values.yaml -n airflow --debug

18 - verifica os pods que ele criou
kubectl get pods -n airflow    

19 - verifica os serviços que ele criou
kubectl get svc -n airflow

20 - verifica p pvc que ele criou (guarda os dados do postgresql em caso de queda do pod em um disco interno) 
kubectl get pvc -n airflow

21 - acessando o airflow
http://a99ceaa1bc99740e5a2535b0769f61ab-820017828.us-east-1.elb.amazonaws.com:8080/login/?next=http%3A%2F%2Fa99ceaa1bc99740e5a2535b0769f61ab-820017828.us-east-1.elb.amazonaws.com%3A8080%2Fhome

user: carlos.ezequiel
senha: puc@123

22 - cria uma variavel de conexao no airflow chamada my_aws


99 - deletando o cluster
eksctl delete cluster --region=us-east-1 --name=kubece